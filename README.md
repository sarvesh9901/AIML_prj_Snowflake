

# ğŸ“˜ Customer Churn Prediction using Snowflake & Snowpark (End-to-End ML Project)

## ğŸš€ Overview

This project is an **end-to-end AI/ML Proof of Concept (POC)** developed entirely inside **Snowflake**, without using any local compute environments or external tools.

The objective is to demonstrate how Snowflake can be used for:

* Data ingestion
* Data engineering
* Machine learning model training
* Prediction storage
  â€” using **Snowpark Python** within Snowflake itself.

This project was created as part of the evaluation for an **AI/ML Engineer** role with a focus on **Snowflake + ML Operations**.

---

# ğŸ¯ Problem Statement â€“ Predict Customer Churn

Businesses face revenue loss when customers stop using their services.
The goal of this project is to **predict if a customer is likely to churn**, based on numeric, categorical, and behavioral features.

### âœ” Why it matters?

* Helps reduce churn
* Improves customer retention
* Enables personalized offers
* Supports better business decisions

---

# ğŸ› ï¸ Solution Approach

This POC implements a complete ML lifecycle inside Snowflake:

### ğŸ”¹ 1. Data Generation (Mockaroo)

Synthetic churn dataset generated with fields like age, income, spend, tenure, membership tier, etc.

### ğŸ”¹ 2. Snowflake Setup

Created using SQL:

* Warehouse: `ML_WH`
* Database: `ML_PROJECT`
* Schema: `CHURN_POC`
* Table: `CUSTOMERS`

### ğŸ”¹ 3. Data Loading

Mockaroo CSV was uploaded directly using **Snowsight â†’ Load Data**.

### ğŸ”¹ 4. ML Pipeline in Snowpark Python

A **Snowpark Python Worksheet** was used to perform:

* Load data from Snowflake table
* Convert to pandas for modeling
* Encode features (OneHotEncoding)
* Train a RandomForestClassifier
* Evaluate model accuracy
* Generate predictions
* Store results back into Snowflake

### ğŸ”¹ 5. Prediction Storage

Predictions are saved into a Snowflake table:
`CUSTOMER_CHURN_PREDICTIONS`

---

# ğŸ“‚ Files Included in This Repository

This repository contains:

### ğŸ“Œ **1. SQL Scripts**

All SQL scripts used to create:

* Warehouse
* Database
* Schema
* Customer table

These are the exact scripts executed inside Snowflake.

---

### ğŸ“Œ **2. Snowpark Python Notebook**

A notebook (exported from Snowflake) that contains:

* Data loading
* Model training
* Preprocessing
* Prediction generation
* Writing predictions back into Snowflake

This is the same code executed in the **Snowpark Python Worksheet**.

---

### ğŸ“Œ **3. Sample Mockaroo Data**

* A sample CSV or schema file used to generate the customer dataset.
* Helps evaluators replicate or understand the dataset used.

---

# ğŸ“Š Dataset Description (Mockaroo)

| Column             | Description                        |
| ------------------ | ---------------------------------- |
| customer_id        | Unique ID                          |
| gender             | Male/Female                        |
| age                | 18â€“70                              |
| income             | Annual income                      |
| tenure_months      | Duration of customer relationship  |
| monthly_spend      | Monthly spending                   |
| num_tickets_raised | Support ticket count               |
| membership_tier    | Basic / Standard / Premium / Elite |
| churn              | 0 or 1 (target variable)           |

---

# ğŸ§  ML Model (Snowpark Python)

### âœ” Preprocessing

* OneHotEncoding for `gender` & `membership_tier`
* Numeric features used directly

### âœ” Model

**RandomForestClassifier**

* n_estimators=150
* max_depth=None
* random_state=42

### âœ” Output

Two columns generated:

* `predicted_churn`
* `predicted_churn_probability`

Stored in:
`CUSTOMER_CHURN_PREDICTIONS`

---

# ğŸ§ª Results

### ğŸ”¸ Model Accuracy

~80â€“90% depending on dataset randomness.

### ğŸ”¸ Prediction Table Sample

| customer_id | predicted_churn | predicted_churn_probability |
| ----------- | --------------- | --------------------------- |
| 101         | 1               | 0.82                        |
| 102         | 0               | 0.10                        |
| ...         | ...             | ...                         |

---

# â–¶ï¸ How to Run This Project

### **Prerequisites**

* Snowflake free trial account
* Mockaroo dataset

### **Steps**

1. Run the SQL scripts from `sql_scripts/` folder
2. Upload the dataset using Snowflake **Load Data**
3. Open Snowpark Python Worksheet
4. Run the notebook provided in `python_notebook/`
5. Validate output in:

   ```
   ML_PROJECT.CHURN_POC.CUSTOMER_CHURN_PREDICTIONS
   ```

Everything runs fully inside Snowflake â€” **no local system required**.

---

# ğŸ“Œ Key Highlights

âœ” Fully Snowflake-native ML pipeline
âœ” Snowpark Python for model training
âœ” End-to-end data engineering + ML workflow
âœ” Synthetic dataset creation with Mockaroo
âœ” Clear predictions stored inside Snowflake
âœ” No external compute or notebook used

---

# ğŸ Conclusion

This POC effectively demonstrates how Snowflake can be used as a complete machine learning platform including:

* Data ingestion
* Feature engineering
* ML model training
* Prediction storage

It showcases strong cloud-native AI/ML engineering skills aligned to the role requirements.

---

# ğŸ‘¨â€ğŸ’» Author

**Sarvesh**
AI/ML Engineer Candidate

